
seed: 42

task:
  name: "01_walking"

  vec_task: {}
 


policy: 


  actor_net:
    - name: actor_linear_obs_net
      input: 
          - obs: linear
      mlp:
          units: [512, 256, 128]
          activation: elu
          initializer: default
    
  normalize_input: True


algo:
  name: "PPO"
  grad_norm: 1.0
  gamma: 0.99
  mixed_precision: True
  gae_lambda: 0.95
  truncate_grads: True
  normalize_value: True
  normalize_advantage: True
  value_size: 1 # the amount of values the critic outputs
  weight_decay: 0.0
  learning_rate: 5e-4
  lr_schedule: adaptive
  kl_threshold: 0.008
  e_clip: 0.2
  clip_value: True
  horizon_length: 32
  minibatch_size: 32768
  mini_epochs: 5
  reward_shaper:
    scale_value: 0.01
    shift_value: 0

  value_bootstrap: True
  critic_coef: 4
  entropy_coef: 0

  bounds_loss_coef: 0.0001
