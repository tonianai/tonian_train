{"run/last_1000_obj_ep_reward": 0.0, "_timestamp": 1690983603.8019373, "run/step_reward": 0.11294759809970856, "run/episode_rewards": 524.8161153885925, "run/objective_episode_rewards": 0.0, "run/steps_per_episode": 147.75728155339806, "run_reward_alive_reward": 2.0, "run_reward_upright_punishment": -0.2825528113171458, "run_reward_direction_reward": 4.745763391256332, "run_reward_jitter_punishment": -0.12680433923378587, "run_reward_energy_punishment": -0.5864955354481936, "run_reward_arm_use_punishment": -0.08765619713813066, "run_reward_arm_position_punishment": -0.2306335442699492, "run_reward_overextend_punishment": -1.791662197560072, "run_reward_contact_punishment": -0.0, "run_reward_total_reward": 5.749910705257207, "z_speed/steps_per_second": 42447.51881244873, "z_speed/time_on_rollout": 0.7044751644134521, "z_speed/time_on_train": 0.0674898624420166, "z_speed/step_time": 0.6481828689575195, "z_speed/time_fraq_on_rollout": 0.912573937815641, "z_speed/time_fraq_on_train": 0.08742606218435903, "losses/a_loss": 0.001389145734719932, "losses/c_loss": 0.05998675152659416, "losses/entropy": 10.601272583007812, "info/last_lr": 9.876543209876547e-05, "info/lr_mul": 1.0, "info/e_clip": 0.2, "info/kl": 0.010251144878566265, "info/epochs": 1990, "losses/bounds_loss": 169.95013427734375, "_runtime": 1603.8729753494263, "_step": 65208320}