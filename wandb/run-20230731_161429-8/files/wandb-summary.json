{"run/last_1000_obj_ep_reward": 0.0, "_timestamp": 1690813683.5062907, "run/step_reward": 0.07189462333917618, "run/episode_rewards": 201.1351624256612, "run/objective_episode_rewards": 0.0, "run/steps_per_episode": 85.97872340425532, "run_reward_alive_reward": 2.0, "run_reward_upright_punishment": -0.1658079787157476, "run_reward_direction_reward": 2.7446435168385506, "run_reward_jitter_punishment": -0.17575421510264277, "run_reward_energy_punishment": -0.44691069796681404, "run_reward_arm_use_punishment": -0.08542763534933329, "run_reward_arm_position_punishment": -0.32365027349442244, "run_reward_overextend_punishment": -1.0170591063797474, "run_reward_contact_punishment": -0.0, "run_reward_total_reward": 3.956170625053346, "z_speed/steps_per_second": 10311.876114890061, "z_speed/time_on_rollout": 3.11376953125, "z_speed/time_on_train": 0.06392574310302734, "z_speed/step_time": 3.055772066116333, "z_speed/time_fraq_on_rollout": 0.9798829851247953, "z_speed/time_fraq_on_train": 0.02011701487520464, "losses/a_loss": -0.002959951525554061, "losses/c_loss": 0.14167170226573944, "losses/entropy": 17.603063583374023, "info/last_lr": 0.0005000000000000001, "info/lr_mul": 1.0, "info/e_clip": 0.2, "info/kl": 0.009075414389371872, "info/epochs": 254, "losses/bounds_loss": 33.164730072021484, "_runtime": 813.8847887516022, "_step": 8323072, "_wandb": {"runtime": 815}}