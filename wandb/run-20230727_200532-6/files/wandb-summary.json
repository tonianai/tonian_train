{"run/last_1000_obj_ep_reward": 0.0, "_timestamp": 1690481857.6927783, "run/step_reward": 0.0558362677693367, "run/episode_rewards": 149.85472103993558, "run/objective_episode_rewards": 0.0, "run/steps_per_episode": 64.90558766859345, "run_reward_alive_reward": 2.0, "run_reward_upright_punishment": -0.08346991101279855, "run_reward_direction_reward": 2.0019179470837116, "run_reward_jitter_punishment": -0.18541158782318234, "run_reward_energy_punishment": -0.4336168793961406, "run_reward_arm_use_punishment": -0.08687235368415713, "run_reward_arm_position_punishment": -0.3765065371990204, "run_reward_overextend_punishment": -0.68125269562006, "run_reward_contact_punishment": -0.0, "run_reward_total_reward": 3.29941956885159, "z_speed/steps_per_second": 9758.301522310889, "z_speed/time_on_rollout": 3.2990903854370117, "z_speed/time_on_train": 0.05887103080749512, "z_speed/step_time": 3.212374210357666, "z_speed/time_fraq_on_rollout": 0.9824682229751955, "z_speed/time_fraq_on_train": 0.017531777024804407, "losses/a_loss": -0.0001391849509673193, "losses/c_loss": 0.12238500267267227, "losses/entropy": 17.819320678710938, "info/last_lr": 0.00033333333333333343, "info/lr_mul": 1.0, "info/e_clip": 0.2, "info/kl": 0.019150247797369957, "info/epochs": 225, "losses/bounds_loss": 30.695636749267578, "_runtime": 724.7840993404388, "_step": 7372800, "_wandb": {"runtime": 725}}