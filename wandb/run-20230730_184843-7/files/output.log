Learning Rate
5e-4
RunningMeanStd:  (1,)
Reward to beat
None
 Run: 7    |     Iteration: 1     |    Steps Trained: 3.277e+04     |     Steps per Second: 7479     |     Time Spend on Rollout: 98.14%
 Run: 7    |     Iteration: 2     |    Steps Trained: 6.554e+04     |     Steps per Second: 9601     |     Time Spend on Rollout: 98.09%
 Run: 7    |     Iteration: 3     |    Steps Trained: 9.830e+04     |     Steps per Second: 10024     |     Time Spend on Rollout: 98.18%
 Run: 7    |     Iteration: 4     |    Steps Trained: 1.311e+05     |     Steps per Second: 9986     |     Time Spend on Rollout: 98.20%
 Run: 7    |     Iteration: 5     |    Steps Trained: 1.638e+05     |     Steps per Second: 9883     |     Time Spend on Rollout: 98.04%
 Run: 7    |     Iteration: 6     |    Steps Trained: 1.966e+05     |     Steps per Second: 9331     |     Time Spend on Rollout: 98.09%
 Run: 7    |     Iteration: 7     |    Steps Trained: 2.294e+05     |     Steps per Second: 9048     |     Time Spend on Rollout: 98.19%
 Run: 7    |     Iteration: 8     |    Steps Trained: 2.621e+05     |     Steps per Second: 9214     |     Time Spend on Rollout: 98.17%
 Run: 7    |     Iteration: 9     |    Steps Trained: 2.949e+05     |     Steps per Second: 9176     |     Time Spend on Rollout: 98.16%
 Run: 7    |     Iteration: 10     |    Steps Trained: 3.277e+05     |     Steps per Second: 9336     |     Time Spend on Rollout: 97.85%
 Run: 7    |     Iteration: 11     |    Steps Trained: 3.604e+05     |     Steps per Second: 8715     |     Time Spend on Rollout: 98.08%
save best policy
 Run: 7    |     Iteration: 12     |    Steps Trained: 3.932e+05     |     Steps per Second: 8889     |     Time Spend on Rollout: 97.79%
 Run: 7    |     Iteration: 13     |    Steps Trained: 4.260e+05     |     Steps per Second: 9108     |     Time Spend on Rollout: 98.05%
 Run: 7    |     Iteration: 14     |    Steps Trained: 4.588e+05     |     Steps per Second: 9082     |     Time Spend on Rollout: 98.03%
Traceback (most recent call last):
  File "testing_env/run_test.py", line 149, in <module>
    train(args['cfg'], args.get('seed', 0), {}, args['headless'], args.get('batch_id', None), args.get('model_out', None),  True)
  File "testing_env/run_test.py", line 132, in train
    algo.train(max_steps)
  File "/home/schmijo/Documents/Workspace/tonian_train/tonian_train/algorithms.py", line 687, in train
    step_time, play_time, update_time, sum_time, a_losses, c_losses, b_losses,  entropies, kls, last_lr, lr_mul = self.train_epoch()
  File "/home/schmijo/Documents/Workspace/tonian_train/tonian_train/algorithms.py", line 607, in train_epoch
    batch_dict = self.play_steps()
  File "/home/schmijo/Documents/Workspace/tonian_train/tonian_train/algorithms.py", line 384, in play_steps
    obs, rewards, self.dones, infos, reward_constituents = self.env_step(actions)
  File "/home/schmijo/Documents/Workspace/tonian_train/tonian_train/algorithms.py", line 335, in env_step
    obs, rewards, dones, infos, reward_constituents = self.env.step(actions)
  File "/home/schmijo/Documents/Workspace/tonian_train/testing_env/base_env/vec_task.py", line 328, in step
    self.gym.simulate(self.sim)
KeyboardInterrupt