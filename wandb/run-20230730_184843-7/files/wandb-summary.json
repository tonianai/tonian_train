{"run/last_1000_obj_ep_reward": 0.0, "_timestamp": 1690735777.4893293, "run/step_reward": 0.011685952544212341, "run/episode_rewards": 4.236484378576279, "run/objective_episode_rewards": 0.0, "run/steps_per_episode": 20.3671875, "run_reward_alive_reward": 2.0, "run_reward_upright_punishment": -0.11171644530259073, "run_reward_direction_reward": 0.7834914084523916, "run_reward_jitter_punishment": -0.20936464425176382, "run_reward_energy_punishment": -0.4383859969675541, "run_reward_arm_use_punishment": -0.09798188041895628, "run_reward_arm_position_punishment": -0.7055486422032118, "run_reward_overextend_punishment": -0.6274192538112402, "run_reward_contact_punishment": -0.0, "run_reward_total_reward": 2.024024321930483, "z_speed/steps_per_second": 9081.894577458399, "z_speed/time_on_rollout": 3.536801815032959, "z_speed/time_on_train": 0.07125592231750488, "z_speed/step_time": 3.4730217456817627, "z_speed/time_fraq_on_rollout": 0.9802508918912615, "z_speed/time_fraq_on_train": 0.01974910810873854, "losses/a_loss": 0.005053489934653044, "losses/c_loss": 0.18587316572666168, "losses/entropy": 23.26070785522461, "info/last_lr": 0.0016875000000000006, "info/lr_mul": 1.0, "info/e_clip": 0.2, "info/kl": 0.03047037124633789, "info/epochs": 14, "losses/bounds_loss": 19.79863166809082, "_runtime": 53.542094230651855, "_step": 458752, "_wandb": {"runtime": 54}}