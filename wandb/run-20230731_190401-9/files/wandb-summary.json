{"run/last_1000_obj_ep_reward": 0.0, "_timestamp": 1690823048.8373644, "run/step_reward": -0.1564590334892273, "run/episode_rewards": -97.73228341384616, "run/objective_episode_rewards": 0.0, "run/steps_per_episode": 21.99791013584117, "run_reward_alive_reward": 2.0, "run_reward_upright_punishment": -0.1756995817704592, "run_reward_direction_reward": 1.284771602600813, "run_reward_jitter_punishment": -0.20428353501483798, "run_reward_energy_punishment": -0.4419898772612214, "run_reward_arm_use_punishment": -0.09552696300670505, "run_reward_arm_position_punishment": -5.815814070403576, "run_reward_overextend_punishment": -0.6801693011075258, "run_reward_contact_punishment": -0.0, "run_reward_total_reward": 2.4627986085542943, "z_speed/steps_per_second": 7325.825804565052, "z_speed/time_on_rollout": 4.408856630325317, "z_speed/time_on_train": 0.0640861988067627, "z_speed/step_time": 4.35791540145874, "z_speed/time_fraq_on_rollout": 0.9856724753132609, "z_speed/time_fraq_on_train": 0.01432752468673914, "losses/a_loss": 0.031705278903245926, "losses/c_loss": 2.356354236602783, "losses/entropy": 24.124914169311523, "info/last_lr": 0.0011250000000000001, "info/lr_mul": 1.0, "info/e_clip": 0.2, "info/kl": 0.01834421046078205, "info/epochs": 1, "losses/bounds_loss": 19.94188690185547, "_runtime": 7.654764413833618, "_step": 32768, "_wandb": {"runtime": 8}}