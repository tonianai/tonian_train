run/episode_rewards,run/steps_per_episode,run_rewards_per_step/stay/alive_reward,run_rewards_per_step/run/alive_reward,run_rewards_per_step/stay/upright_punishment,run_rewards_per_step/run/upright_punishment,run_rewards_per_step/stay/direction_reward,run_rewards_per_step/run/direction_reward,run_rewards_per_step/stay/general_vel_reward,run_rewards_per_step/run/general_vel_reward,run_rewards_per_step/stay/jitter_punishment,run_rewards_per_step/run/jitter_punishment,run_rewards_per_step/stay/overextend_punishment,run_rewards_per_step/run/overextend_punishment,run_rewards_per_step/stay/energy_punishment,run_rewards_per_step/run/energy_punishment,run_rewards_per_step/stay/total_reward,run_rewards_per_step/run/total_reward,z_speed/steps_per_second,z_speed/time_on_rollout,z_speed/time_on_train,z_speed/step_time,z_speed/time_fraq_on_rollout,z_speed/time_fraq_on_train,losses/a_loss,losses/c_loss,losses/entropy,info/last_lr,info/lr_mul,info/e_clip,info/kl,info/epochs,losses/bounds_loss
58429.47265625,2972.0,3.0,3.0,-0.0039372764877043664,-0.025234320550225675,0.0,6.800656318664551,-0.13040700228884816,0.0,-0.17344973282888532,-0.21324956277385354,-0.05597419466357678,-0.3234566617757082,-0.11605206341482699,-0.027361752523574978,2.373273476958275,8.62943634390831,44824.5727778662,6.061828851699829,0.09411358833312988,6.011724472045898,0.9904227765093777,0.10730955823066086,0.05062466487288475,2.4822561740875244,24.124204635620117,0.0037968750000000016,1.0,0.2,0.08132310956716537,5545,"tensor(32.1084, device='cuda:0', grad_fn=<MeanBackward0>)"
