run/episode_rewards,run/steps_per_episode,run_rewards_per_step/alive_reward,run_rewards_per_step/upright_punishment,run_rewards_per_step/jitter_punishment,run_rewards_per_step/forward_facing_vel_reward,run_rewards_per_step/target_velocity_reward,run_rewards_per_step/energy_punishment,run_rewards_per_step/arm_use_punishment,run_rewards_per_step/overextend_punishment,run_rewards_per_step/contact_punishment,run_rewards_per_step/total_reward,z_speed/steps_per_second,z_speed/time_on_rollout,z_speed/time_on_train,z_speed/step_time,z_speed/time_fraq_on_rollout,z_speed/time_fraq_on_train,losses/a_loss,losses/c_loss,losses/entropy,info/last_lr,info/lr_mul,info/e_clip,info/kl,info/epochs,losses/bounds_loss
5327.042856852214,673.6666666666666,2.0,-0.003271798494097311,-0.1281708455644548,0.0,0.0,-0.0995427502784878,-0.0,-0.07496936130337417,0.0,1.69008157402277,18006.0851535527,1.664750576019287,0.15507864952087402,1.4735443592071533,0.914783954810461,0.08521604518953894,-0.00457020616158843,0.01732054352760315,14.994505882263184,0.00022499999999999997,1.0,0.2,0.01645076833665371,817,"tensor(25.6586, device='cuda:0', grad_fn=<MeanBackward0>)"
