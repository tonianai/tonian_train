{algo: {bounds_loss_coef: 0.0001, clip_value: true, critic_coef: 4, e_clip: 0.2, entropy_coef: 0,
    gae_lambda: 0.95, gamma: 0.99, grad_norm: 1.0, horizon_length: 32, kl_threshold: 0.008,
    learning_rate: 5e-4, lr_schedule: adaptive, mini_epochs: 5, minibatch_size: 32768,
    mixed_precision: true, name: PPO, normalize_advantage: true, normalize_value: true,
    reward_shaper: {scale_value: 0.01, shift_value: 0}, truncate_grads: true, value_bootstrap: true,
    value_size: 1, weight_decay: 0.0}, policy: {actor_net: [{input: [{obs: linear}],
        mlp: {activation: elu, initializer: default, units: [512, 256, 128]}, name: actor_linear_obs_net}],
    normalize_input: true}, seed: 42, task: {mk1: {agent: {default_friction: {dist_type: gaussian,
          mean: 1.5, std: 0.5}, default_mass_std: 0.1, default_motor_power: 1000,
        frictions: {foot: {dist_type: gaussian, mean: 100, std: 2}, foot_2: {dist_type: gaussian,
            mean: 100, std: 2}}, motor_power_std: 2, motor_powers: {left_arm_rotate: 200,
          left_elbow: 400, left_foot: 300, left_hip_a: 1000, left_hip_b: 1000, left_knee: 1500,
          left_shoulder_a: 400, left_shoulder_b: 400, right_arm_rotate: 200, right_elbow: 400,
          right_foot: 300, right_hip_a: 500, right_hip_b: 500, right_knee: 1500, right_shoulder_a: 400,
          right_shoulder_b: 400, torso: 300}}, initial_velocities: [{dist_type: gaussian,
          mean: 0, std: 0.4}, {dist_type: gaussian, mean: -0.5, std: 0.8}, 0], pure_shapes: false,
      spawn_height: 1.65}, mk1_walking: {reward_weighting: {alive_reward: 2, arm_position_cost: 1,
        arm_use_cost: 0.3, contact_punishment: 0, death_cost: 10, death_height: 1.25,
        die_on_contact: false, directional_factor: 0.8, energy_cost: 0.005, jitter_cost: 0.25,
        overextend_cost: 7, upright_punishment_factor: 20, zero_clip_direction_reward: true}},
    name: 02_mk1_running, vec_task: {num_envs: 1024}}}
